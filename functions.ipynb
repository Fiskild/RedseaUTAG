{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr_R-EshQiNC"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I10_r10Tl631"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install squidpy parmap imantics scanpy igraph leidenalg umap imagecodecs GDAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq8UH4HkTLxw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# packages\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "import random\n",
        "import base64\n",
        "import typing as tp\n",
        "import warnings\n",
        "import pickle\n",
        "\n",
        "# Data handling and analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from scipy.special import softmax\n",
        "from scipy.linalg import sqrtm\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# Machine learning and statistics\n",
        "import sklearn\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.cluster import KMeans\n",
        "import umap\n",
        "import igraph as ig\n",
        "import leidenalg\n",
        "\n",
        "# Image processing and visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.figure import Figure as _Figure\n",
        "import seaborn as sns\n",
        "import PIL\n",
        "from PIL import Image, ImageSequence, ImageOps\n",
        "import imagecodecs\n",
        "import skimage\n",
        "from skimage import io as tiff\n",
        "from skimage import measure, morphology\n",
        "from skimage.segmentation import relabel_sequential\n",
        "from skimage.measure import label, regionprops\n",
        "import imageio\n",
        "\n",
        "# Bioinformatics and spatial data analysis\n",
        "import scanpy as sc\n",
        "import anndata\n",
        "from anndata import AnnData\n",
        "import squidpy as sq\n",
        "\n",
        "# Geometry and masks\n",
        "from shapely.geometry import Polygon\n",
        "from imantics import Mask\n",
        "\n",
        "# Progress bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Parallel processing\n",
        "import parmap\n",
        "import networkx as nx\n",
        "import pathlib\n",
        "\n",
        "# image processing\n",
        "from osgeo import gdal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhA7oSaFQmoA"
      },
      "source": [
        "# Data loading and handling funtions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_udI827Ol3v"
      },
      "outputs": [],
      "source": [
        "# Helpers\n",
        "def read_tiff_image(tiff_path):\n",
        "    return tiff.imread(tiff_path)\n",
        "\n",
        "def calculate_centroids(mask):\n",
        "    props = measure.regionprops(mask)\n",
        "    centroids = {prop.label: prop.centroid for prop in props}\n",
        "    return centroids\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions that are specific to the Lung Cancer tissue sample stored in .tif format. Metadata is stored within the data and needs to be extracted. Segmentation mask is stored in the same .tif file as the feature data where nucleus and cytoplasm are seperately labeled."
      ],
      "metadata": {
        "id": "d3jm1ZHI6PPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data_from_gdal_tiffs(feature_tiff_data, mask):\n",
        "    \"\"\"\n",
        "    Extracts data from a mask array and feature TIFF data for use in REDSEA.\n",
        "    Assumes that 'feature_tiff_data' is a 3D numpy array with shape (height, width, num_channels).\n",
        "    \"\"\"\n",
        "    if feature_tiff_data.shape[:2] != mask.shape:\n",
        "        raise ValueError(f\"Intensity image spatial dimensions {feature_tiff_data.shape[:2]} must match mask shape {mask.shape}.\")\n",
        "\n",
        "    num_channels = feature_tiff_data.shape[2]  # Number of channels in the feature image\n",
        "    cell_ids = np.unique(mask[mask != 0])\n",
        "    data = np.zeros((len(cell_ids), num_channels))\n",
        "    dataScaleSize = np.zeros_like(data)\n",
        "    cellSizes = np.zeros((len(cell_ids), 1))\n",
        "\n",
        "    for stat in regionprops(mask):\n",
        "        if stat.area > 0:\n",
        "            idx = cell_ids.tolist().index(stat.label)\n",
        "            for ch in range(num_channels):\n",
        "                cell_data = feature_tiff_data[:, :, ch][mask == stat.label]\n",
        "                data[idx, ch] = cell_data.sum()\n",
        "                dataScaleSize[idx, ch] = data[idx, ch] / stat.area\n",
        "            cellSizes[idx] = stat.area\n",
        "\n",
        "    centroids = calculate_centroids(mask)\n",
        "\n",
        "    return data, cell_ids, centroids, dataScaleSize, cellSizes\n",
        "\n",
        "def tif_create_data(feature_img, cell_ids, centroids, data, channels_df, channel_indices):\n",
        "    \"\"\"\n",
        "    Create an AnnData object using specified channels and mask, utilizing precomputed data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate global means and standard deviations only for specified channels\n",
        "    global_means = np.mean(data, axis=0)\n",
        "    global_stds = np.std(data, axis=0)\n",
        "\n",
        "    # Construct DataFrame for observation metadata\n",
        "    obs_df = pd.DataFrame({\n",
        "        'roi': cell_ids,\n",
        "        'X_centroid': [centroids[id][0] for id in cell_ids],\n",
        "        'Y_centroid': [centroids[id][1] for id in cell_ids]\n",
        "    })\n",
        "\n",
        "    # Ensure that the channel names in the DataFrame are indexed correctly\n",
        "    channel_names = [channels_df.iloc[ch]['channel'] for ch in channel_indices]\n",
        "    var_df = pd.DataFrame({\n",
        "        'mean': global_means,\n",
        "        'std': global_stds\n",
        "    }, index=channel_names)\n",
        "\n",
        "    adata = AnnData(X=data, obs=obs_df, var=var_df)\n",
        "    adata.obsm['spatial'] = np.array(adata.obs[['X_centroid', 'Y_centroid']])\n",
        "\n",
        "    return adata\n",
        "\n",
        "# Functions for extracting the metadata and simplifying the mask so that comparison is possible\n",
        "def read_tiff_all_bands(tiff_path):\n",
        "    \"\"\"\n",
        "    Reads a multi-band TIFF file and stacks all bands into a single 3D numpy array.\n",
        "    \"\"\"\n",
        "    gdal_data = gdal.Open(tiff_path, gdal.GA_ReadOnly)\n",
        "    if gdal_data is None:\n",
        "        raise FileNotFoundError(\"The specified TIFF file could not be opened.\")\n",
        "\n",
        "    num_bands = gdal_data.RasterCount\n",
        "    # Read the first band to initialize the numpy array\n",
        "    band = gdal_data.GetRasterBand(1)\n",
        "    array = band.ReadAsArray()\n",
        "\n",
        "    if num_bands == 1:\n",
        "        return array.reshape(array.shape[0], array.shape[1], 1), gdal_data.GetMetadata()  # Ensure 3D even for one band\n",
        "\n",
        "    # Initialize an empty array with the desired output shape\n",
        "    img_data = np.zeros((array.shape[0], array.shape[1], num_bands), dtype=array.dtype)\n",
        "    img_data[:, :, 0] = array  # Place the first band\n",
        "\n",
        "    for b in range(1, num_bands):\n",
        "        band = gdal_data.GetRasterBand(b + 1)\n",
        "        img_data[:, :, b] = band.ReadAsArray()  # Fill subsequent bands\n",
        "\n",
        "    metadata = gdal_data.GetMetadata()\n",
        "    return img_data, metadata\n",
        "\n",
        "def read_single_band(tiff_path, band_number=1):\n",
        "    \"\"\"\n",
        "    Reads a single band from a multi-band TIFF file.\n",
        "    \"\"\"\n",
        "    gdal_data = gdal.Open(tiff_path, gdal.GA_ReadOnly)\n",
        "    if gdal_data is None:\n",
        "        raise FileNotFoundError(\"The specified TIFF file could not be opened.\")\n",
        "\n",
        "    band = gdal_data.GetRasterBand(band_number)\n",
        "    return band.ReadAsArray()\n",
        "\n",
        "def preprocess_mask(mask, core_label=2, cytoplasm_label=7, connectivity=2):\n",
        "    \"\"\"\n",
        "    Process the mask to label each unique cell distinctly, combining core and cytoplasm into one label per cell,\n",
        "    and then iteratively numbering each cell uniquely.\n",
        "    Assumes labels are used uniformly across all cells.\n",
        "    The background of the resulting mask should be 0, and each cell's pixels will be labeled with a unique integer.\n",
        "    \"\"\"\n",
        "    # Create a combined mask where both core and cytoplasm are considered as one entity per cell\n",
        "    combined_cell_mask = np.logical_or(mask == core_label, mask == cytoplasm_label)\n",
        "\n",
        "    # Label the combined cell regions\n",
        "    labeled_mask, num_features = label(combined_cell_mask, connectivity=connectivity, return_num=True)\n",
        "\n",
        "    # Relabel the mask sequentially to ensure continuous numbering starting from 1\n",
        "    labeled_mask, forward_map, inverse_map = relabel_sequential(labeled_mask)\n",
        "\n",
        "    return labeled_mask\n",
        "\n",
        "def crop_tiff_to_match_mask(img_data, mask_shape):\n",
        "    \"\"\"\n",
        "    Crop the multi-channel TIFF data to match the dimensions of the mask.\n",
        "    \"\"\"\n",
        "    # Check if the spatial dimensions of the image data are at least as large as those of the mask\n",
        "    if img_data.shape[0] >= mask_shape[0] and img_data.shape[1] >= mask_shape[1]:\n",
        "        # Crop the image data to match the mask's dimensions\n",
        "        cropped_img_data = img_data[:mask_shape[0], :mask_shape[1], :]\n",
        "        return cropped_img_data\n",
        "    else:\n",
        "        raise ValueError(\"Image data is smaller than mask dimensions or has incorrect shape.\")"
      ],
      "metadata": {
        "id": "0vL_CBOB1WEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions specific to the urothelial carcinoma tissue sample stored in .tiff format. Metadata is supplied as a .csv file. Segmentation mask is stored in a separate .tiff file with incremental numbering of different cell objects."
      ],
      "metadata": {
        "id": "Tfrvcocw6pZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for use in utag after redsea\n",
        "def extract_data_from_tiffs(feature_tiff_path, mask, channel_indices):\n",
        "    \"\"\"\n",
        "    Extracts data from mask tiff and feature tiff for use in REDSEA\n",
        "    Only data from specified channel indices are processed and extracted.\n",
        "    \"\"\"\n",
        "    feature_img = read_tiff_image(feature_tiff_path)\n",
        "    cell_ids = np.unique(mask[mask != 0])\n",
        "    num_channels = len(channel_indices)  # Process only the non-noisy channels\n",
        "    data = np.zeros((len(cell_ids), num_channels))\n",
        "    dataScaleSize = np.zeros_like(data)\n",
        "    cellSizes = np.zeros((len(cell_ids), 1))\n",
        "\n",
        "    for stat in measure.regionprops(mask):\n",
        "        if stat.area > 0:\n",
        "            idx = cell_ids.tolist().index(stat.label)\n",
        "            for i, ch in enumerate(channel_indices):\n",
        "                cell_data = feature_img[ch, :, :][mask == stat.label]\n",
        "                data[idx, i] = cell_data.sum()  # Use i to index into data since it's the index in filtered channels\n",
        "                dataScaleSize[idx, i] = data[idx, i] / stat.area\n",
        "            cellSizes[idx] = stat.area\n",
        "\n",
        "    centroids = calculate_centroids(mask)\n",
        "    return data, cell_ids, centroids, dataScaleSize, cellSizes\n",
        "\n",
        "def create_anndata(data, cell_ids, centroids, means, stdevs, channels_df, valid_indices):\n",
        "    \"\"\"\n",
        "    Create adata object on REDSEA compensated data ensuring indices are consistent.\n",
        "    \"\"\"\n",
        "    # Create observation DataFrame filtered by valid_indices\n",
        "    obs_df = pd.DataFrame({\n",
        "        'roi': cell_ids[valid_indices],\n",
        "        'X_centroid': [centroids[id][1] for id in cell_ids[valid_indices]],\n",
        "        'Y_centroid': [centroids[id][0] for id in cell_ids[valid_indices]]\n",
        "    })\n",
        "\n",
        "    # Create variable DataFrame using channel data\n",
        "    var_df = pd.DataFrame({\n",
        "        'mean': means,\n",
        "        'std': stdevs\n",
        "    }, index=channels_df['channel'])\n",
        "\n",
        "    adata = AnnData(X=data, obs=obs_df, var=var_df)\n",
        "    adata.obsm['spatial'] = np.array(obs_df[['Y_centroid', 'X_centroid']])\n",
        "    return adata\n",
        "\n",
        "# for use in utag without prior application of redsea\n",
        "def utag_extract_data_from_tiffs(feature_img, mask, channel_indices):\n",
        "    \"\"\"\n",
        "    Extract data from specified channels in a TIFF file for use in creating an AnnData object for UTAG analysis.\n",
        "    \"\"\"\n",
        "    centroids = calculate_centroids(mask)\n",
        "    cell_ids = np.unique(mask[mask != 0])  # Exclude background\n",
        "    num_channels = len(channel_indices)\n",
        "    data = np.zeros((len(cell_ids), num_channels))\n",
        "    global_means = np.zeros(num_channels)\n",
        "    global_stds = np.zeros(num_channels)\n",
        "\n",
        "    for i, channel in enumerate(channel_indices):\n",
        "        channel_data = feature_img[channel, :, :]\n",
        "        global_means[i] = np.mean(channel_data[mask != 0])\n",
        "        global_stds[i] = np.std(channel_data[mask != 0])\n",
        "\n",
        "        for j, cell_id in enumerate(cell_ids):\n",
        "            cell_data = channel_data[mask == cell_id]\n",
        "            data[j, i] = np.mean(cell_data)\n",
        "\n",
        "    return data, cell_ids, centroids, global_means, global_stds\n",
        "\n",
        "def utag_create_anndata(feature_img, mask, channels_df):\n",
        "    \"\"\"\n",
        "    Create an AnnData object using specified channels and mask.\n",
        "    \"\"\"\n",
        "    remaining_channels = [i for i in range(len(channels_df)) if channels_df.iloc[i]['channel'] not in noisy_channels]\n",
        "    data, cell_ids, centroids, global_means, global_stds = utag_extract_data_from_tiffs(feature_img, mask, remaining_channels)\n",
        "\n",
        "    obs_df = pd.DataFrame({\n",
        "        'roi': cell_ids,\n",
        "        'X_centroid': [centroids[id][0] for id in cell_ids],\n",
        "        'Y_centroid': [centroids[id][1] for id in cell_ids]\n",
        "    })\n",
        "\n",
        "    var_df = pd.DataFrame({\n",
        "        'mean': global_means,\n",
        "        'std': global_stds\n",
        "    }, index=[channels_df.iloc[ch]['channel'] for ch in remaining_channels])\n",
        "\n",
        "    adata = AnnData(X=data, obs=obs_df, var=var_df)\n",
        "    adata.obsm['spatial'] = np.array(adata.obs[['Y_centroid', 'X_centroid']])\n",
        "\n",
        "    return adata"
      ],
      "metadata": {
        "id": "iFHjro2Q6pnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#REDSEA functions"
      ],
      "metadata": {
        "id": "G5iEhMXP6rHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFHBbiGgk3sE"
      },
      "outputs": [],
      "source": [
        "def ismember(a, b):\n",
        "    \"\"\"\n",
        "    Determines the indices of the first occurrence of elements of list 'a' in list 'b'.\n",
        "    If an element of 'a' is not found in 'b','None' is returned for that element.\n",
        "    \"\"\"\n",
        "    index_map = {}\n",
        "    for i, element in enumerate(b):\n",
        "        if element not in index_map:\n",
        "            index_map[element] = i\n",
        "    return [index_map.get(item, None) for item in a]\n",
        "\n",
        "def compute_cell_contact_matrix(mask):\n",
        "    \"\"\"\n",
        "    Loads the segmentation mask from a TIFF file, prepares it by removing the background label,\n",
        "    adds a border for safe access, and computes the cell contact matrix.\n",
        "    \"\"\"\n",
        "    # Load the mask and prepare it\n",
        "    #mask = read_tiff_image(mask_path)\n",
        "    unique_labels = np.unique(mask)\n",
        "    if 0 in unique_labels:\n",
        "        unique_labels = unique_labels[1:]  # Remove background label if present\n",
        "\n",
        "    # Create a mapping from label to index\n",
        "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    cellNum = len(unique_labels)  # This is the number of cells\n",
        "\n",
        "    # Prepare the mask with a border for safe matrix access\n",
        "    mask_border = np.pad(mask, pad_width=1, mode='constant', constant_values=0)\n",
        "    rowNum, colNum = mask_border.shape\n",
        "\n",
        "    # Initialize the cell-cell shared perimeter matrix container with correct size\n",
        "    cellPairMap = np.zeros((cellNum, cellNum))\n",
        "\n",
        "    # Compute the cell-cell contact matrix\n",
        "    for i in range(1, rowNum - 1):  # Adjust for the border\n",
        "        for j in range(1, colNum - 1):  # Adjust for the border\n",
        "            if mask_border[i, j] == 0:\n",
        "                tempMatrix = mask_border[i-1:i+2, j-1:j+2]  # 3x3 window around the boundary\n",
        "                tempFactors = np.unique(tempMatrix)\n",
        "                tempFactors = [label for label in tempFactors if label > 0]  # Filter out the background\n",
        "\n",
        "                # Update the cellPairMap using mapped indices\n",
        "                for k in range(len(tempFactors)):\n",
        "                    for l in range(k + 1, len(tempFactors)):\n",
        "                        idx_k = label_to_index[tempFactors[k]]\n",
        "                        idx_l = label_to_index[tempFactors[l]]\n",
        "                        cellPairMap[idx_k, idx_l] += 1\n",
        "                        cellPairMap[idx_l, idx_k] += 1  # Ensure symmetry\n",
        "\n",
        "    np.fill_diagonal(cellPairMap, 0)  # Optionally remove diagonal to ignore self-pairing\n",
        "    return cellPairMap, cellNum, rowNum, colNum\n",
        "\n",
        "def process_boundary_signals(mask, countsNoNoise, cellNum, rowNum, colNum, elementShape, elementSize, clusterChannels):\n",
        "    \"\"\"\n",
        "    Process boundary signals in a mask to update cluster channels based on element shape and size.\n",
        "    \"\"\"\n",
        "    MIBIdataNearEdge1 = np.zeros((cellNum,len(clusterChannels)))\n",
        "    # Pre-calculate shapes based on elementShape\n",
        "    if elementShape == 1:  # square\n",
        "        square = skimage.morphology.square(2*elementSize + 1)\n",
        "        square_loc = np.where(square == 1)\n",
        "    elif elementShape == 2:  # diamond\n",
        "        diam = skimage.morphology.diamond(elementSize)\n",
        "        diam_loc = np.where(diam == 1)\n",
        "    else:\n",
        "        print(\"Error: elementShape value not recognized.\")\n",
        "        return\n",
        "\n",
        "    # Process each cell in the mask\n",
        "    for i in range(cellNum):\n",
        "        label = i + 1\n",
        "        tempRow, tempCol = np.where(mask == label)\n",
        "\n",
        "        # Check each point in the cell\n",
        "        for j in range(len(tempRow)):\n",
        "            label_in_shape = []  # Empty list for boundary condition check\n",
        "            # Ensure the operation does not expand outside mask bounds\n",
        "            if (elementSize - 1 < tempRow[j] < rowNum - elementSize - 2 and\n",
        "                elementSize - 1 < tempCol[j] < colNum - elementSize - 2):\n",
        "                ini_point = [tempRow[j] - elementSize, tempCol[j] - elementSize]  # Top-left point\n",
        "\n",
        "                # Apply the pre-calculated shape\n",
        "                if elementShape == 1:  # square\n",
        "                    square_loc_ini_x = [x + ini_point[0] for x in square_loc[0]]\n",
        "                    square_loc_ini_y = [y + ini_point[1] for y in square_loc[1]]\n",
        "                    label_in_shape = [mask[x, y] for x, y in zip(square_loc_ini_x, square_loc_ini_y)]\n",
        "\n",
        "                elif elementShape == 2:  # diamond\n",
        "                    diam_loc_ini_x = [x + ini_point[0] for x in diam_loc[0]]\n",
        "                    diam_loc_ini_y = [y + ini_point[1] for y in diam_loc[1]]\n",
        "                    label_in_shape = [mask[x, y] for x, y in zip(diam_loc_ini_x, diam_loc_ini_y)]\n",
        "\n",
        "            # Update cluster channels if the condition is met\n",
        "            if 0 in label_in_shape:\n",
        "                MIBIdataNearEdge1[i, :] += countsNoNoise[tempRow[j], tempCol[j], :]\n",
        "    return MIBIdataNearEdge1\n",
        "\n",
        "def assemble_df(data_array, suffix):\n",
        "    \"\"\"\n",
        "    Assemble dataframes for each data type, used for RedSEA output\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(data_array, columns=clusterChannels)\n",
        "    return pd.concat([pd.DataFrame(), df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def redsea_compensation(data, mask, filtered_img_data, channels_df, feature_tiff_path, cell_sizes,\n",
        "                        element_shape=2, element_size=2, cluster_channels=None):\n",
        "    \"\"\"\n",
        "    Executes the REDSEA  algorithm for spillover compensation\n",
        "    args:\n",
        "    elementShape (int): The shape of the element used for boundary detection (default: 2, star; 1: square).\n",
        "    elementSize (int): The size of the element used (default: 2).\n",
        "    clusterChannels (array): Specific channels to be normalized. Defaults to all channels if None.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set default cluster_channels if None\n",
        "    if cluster_channels is None:\n",
        "        cluster_channels = channels_df['channel']\n",
        "    normalized_channels = cluster_channels\n",
        "\n",
        "    # Indexing the chosen channels\n",
        "    normalized_channels_inds = np.isin(normalized_channels, cluster_channels)\n",
        "    channel_norm_identity = np.zeros((len(cluster_channels), 1))\n",
        "    channel_norm_identity[normalized_channels_inds, 0] = 1\n",
        "    cluster_channels_inds = np.where(np.isin(cluster_channels, channels_df['channel']))[0]\n",
        "\n",
        "    # Load and process images\n",
        "    if feature_tiff_path.endswith(\".tiff\"):\n",
        "        counts_no_noise = np.transpose(filtered_img_data, (1, 2, 0))\n",
        "    elif feature_tiff_path.endswith(\".tif\"):\n",
        "        counts_no_noise = np.transpose(filtered_img_data, (0, 1, 2))\n",
        "\n",
        "    # Compute cell contact matrix\n",
        "    cell_pair_map, cell_num, row_num, col_num = compute_cell_contact_matrix(mask)\n",
        "\n",
        "    # Calculate boundary effects and normalize\n",
        "    cell_boundary_totals = np.sum(cell_pair_map, axis=0)\n",
        "    epsilon = 1e-10  # Adding a small constant to avoid division by zero\n",
        "    cell_boundary_totals += epsilon\n",
        "    cell_boundary_total_matrix = np.tile(cell_boundary_totals, (cell_num, 1))\n",
        "    cell_pair_norm = np.identity(cell_num) - cell_pair_map / cell_boundary_total_matrix\n",
        "\n",
        "    # Process boundary signals\n",
        "    boundary_data = process_boundary_signals(mask, counts_no_noise, cell_num, row_num, col_num, element_shape, element_size, cluster_channels)\n",
        "\n",
        "    # Boundary signal correction and reinforcement\n",
        "    normalized_data = np.dot(boundary_data.T, cell_pair_norm).T + data\n",
        "    normalized_data = np.clip(normalized_data, 0, None)  # Ensure non-negative values\n",
        "\n",
        "    # Composite the normalized channels with non-normalized channels\n",
        "    rev_channel_norm_identity = 1 - channel_norm_identity\n",
        "    final_normalized_data = (data * rev_channel_norm_identity.T) + (normalized_data * channel_norm_identity.T)\n",
        "\n",
        "    # Scale by size and handle cell identities\n",
        "    data_compen_scale_size = final_normalized_data / cell_sizes\n",
        "    label_identity = np.ones(cell_num)\n",
        "    label_identity[np.sum(data_compen_scale_size[:, cluster_channels_inds], axis=1) < 0.1] = 2  # Exclude low-info cells\n",
        "\n",
        "    # Filter and prepare for output\n",
        "    valid_indices = label_identity == 1\n",
        "    data_compen_scale_size_cells = data_compen_scale_size[valid_indices, :]\n",
        "\n",
        "    # Calculate means and standard deviations for each channel\n",
        "    means = np.mean(data_compen_scale_size_cells, axis=0)\n",
        "    stdevs = np.std(data_compen_scale_size_cells, axis=0)\n",
        "\n",
        "    return data_compen_scale_size_cells, means, stdevs, valid_indices\n"
      ],
      "metadata": {
        "id": "jRQoGFrhX_Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PARC functions"
      ],
      "metadata": {
        "id": "sph3r2tdBa-x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUK6FVd-Sb_0"
      },
      "outputs": [],
      "source": [
        "### HNSW functions\n",
        "class Space:\n",
        "    def __init__(self, dim):\n",
        "        self.dim = dim\n",
        "\n",
        "    def distance(self, vec1, vec2):\n",
        "        raise NotImplementedError(\"Distance function is not implemented.\")\n",
        "\n",
        "class L2Space(Space):\n",
        "    def distance(self, vec1, vec2):\n",
        "        return np.sqrt(np.sum((vec1 - vec2) ** 2))\n",
        "\n",
        "class InnerProductSpace(Space):\n",
        "    def distance(self, vec1, vec2):\n",
        "        # Normalize the vectors to get cosine of the angle\n",
        "        norm1 = np.linalg.norm(vec1)\n",
        "        norm2 = np.linalg.norm(vec2)\n",
        "        if norm1 == 0 or norm2 == 0:\n",
        "            return 1.0  # As the vectors are zero vectors, making them orthogonal (cosine similarity is 0)\n",
        "        cosine_similarity = np.dot(vec1, vec2) / (norm1 * norm2)\n",
        "        return 1 - cosine_similarity\n",
        "\n",
        "class HNSW:\n",
        "    def __init__(self, space='l2', dim=16, M=16, ef_construction=100):\n",
        "        if space == 'l2':\n",
        "            self.space = L2Space(dim)\n",
        "        elif space == 'ip':\n",
        "            self.space = InnerProductSpace(dim)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported space type. Use 'l2' or 'ip'.\")\n",
        "        self.dim = dim\n",
        "        self.data = []\n",
        "        self.ef_construction = ef_construction\n",
        "        self.M = M\n",
        "        self.ef = ef_construction  # Default ef for queries\n",
        "        self.links = {}\n",
        "\n",
        "    def _random_level(self):\n",
        "        \"\"\"\n",
        "        At which level to insert nodes\n",
        "        \"\"\"\n",
        "        level = 0\n",
        "        while np.random.rand() < np.exp(-1) and level < self.mL:\n",
        "            level += 1\n",
        "        return level\n",
        "\n",
        "    def init_index(self, max_elements, ef_construction=None, M=None):\n",
        "        \"\"\"\n",
        "        Initializes the structure for a maximum number of elements.\n",
        "        \"\"\"\n",
        "        if ef_construction:\n",
        "            self.ef_construction = ef_construction\n",
        "        if M:\n",
        "            self.M = M\n",
        "        # Preparing the index structure\n",
        "        self.links = [{i: [] for i in range(self.mL + 1)} for _ in range(max_elements)]\n",
        "\n",
        "    def add_items(self, data, ids=None): #adds instead of placing data\n",
        "        \"\"\"\n",
        "        Adds items to the structure, linking them based on their distance.\n",
        "        \"\"\"\n",
        "        if ids is None:\n",
        "            ids = range(len(self.data), len(self.data) + len(data))\n",
        "        for point, point_id in zip(data, ids):\n",
        "            node_level = self._random_level()\n",
        "            new_node = {'point': point, 'level': node_level}\n",
        "            self.data.append(new_node)\n",
        "            self._insert_point(new_node, point_id)\n",
        "\n",
        "    def _insert_point(self, point_id):\n",
        "        \"\"\"\n",
        "        Inserts a new point and connects it with existing points based on distance.\n",
        "        \"\"\"\n",
        "        if not self.data:\n",
        "            return\n",
        "        point = self.data[point_id]\n",
        "        distances = [self.space.distance(point, self.data[idx]) for idx in range(len(self.data) - 1)]\n",
        "        nearest_indices = np.argsort(distances)[:self.ef_construction]\n",
        "        self.links[point_id] = nearest_indices.tolist()\n",
        "        for idx in nearest_indices:\n",
        "            self.links[idx].append(point_id)\n",
        "            self.links[idx] = list(set(self.links[idx]))[:self.M]\n",
        "\n",
        "    def knn_query(self, data, k=1):\n",
        "        \"\"\"\n",
        "        Queries the structure to find the k-nearest neighbors for given points.\n",
        "        \"\"\"\n",
        "        labels = np.zeros((len(data), k), dtype=int)\n",
        "        distances = np.zeros((len(data), k), dtype=float)\n",
        "        for i, point in enumerate(data):\n",
        "            if not self.data:\n",
        "                continue\n",
        "            dists = [self.space.distance(point, self.data[idx]) for idx in range(len(self.data))]\n",
        "            nearest_indices = np.argsort(dists)[:k]\n",
        "            labels[i, :] = nearest_indices\n",
        "            distances[i, :] = np.array(dists)[nearest_indices]\n",
        "        return labels, distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcQy9Po1kwwh"
      },
      "outputs": [],
      "source": [
        "### PARC functions\n",
        "#combining HNSW and Leiden (as https://github.com/vtraag/leidenalg)\n",
        "class PARC:\n",
        "    def __init__(self, data, true_label=None, dist_std_local=3, jac_std_global='median',\n",
        "                 n_iter_leiden=5, random_seed=42, distance='l2', partition_type=\"ModularityVP\",\n",
        "                 resolution_parameter=1.0, neighbor_graph=None, hnsw_param_ef_construction=150,\n",
        "                 labels=None):\n",
        "        self.data = data\n",
        "        self.true_label = true_label\n",
        "        self.dist_std_local = dist_std_local\n",
        "        self.jac_std_global = jac_std_global\n",
        "        self.n_iter_leiden = n_iter_leiden\n",
        "        self.random_seed = random_seed\n",
        "        self.distance = distance\n",
        "        self.partition_type = partition_type  # Must be \"ModularityVP\" or \"RBVP\"\n",
        "        self.resolution_parameter = resolution_parameter\n",
        "        self.neighbor_graph = neighbor_graph\n",
        "        self.hnsw = HNSW(space=distance, dim=data.shape[1], M=16, ef_construction=hnsw_param_ef_construction)\n",
        "        self.hnsw.init_index(max_elements=len(data), ef_construction=hnsw_param_ef_construction)\n",
        "        self.labels = labels or {}\n",
        "\n",
        "    def run_PARC(self):\n",
        "        if self.neighbor_graph is not None:\n",
        "            graph = self.construct_graph_using_precomputed_neighbors()\n",
        "        else:\n",
        "            graph = self.construct_graph_using_hnsw()\n",
        "\n",
        "        if self.partition_type == \"ModularityVP\":\n",
        "            partition_type = leidenalg.ModularityVertexPartition\n",
        "            partition_kwargs = {}\n",
        "        elif self.partition_type == \"RBVP\":\n",
        "            partition_type = leidenalg.RBConfigurationVertexPartition\n",
        "            partition_kwargs = {'resolution_parameter': self.resolution_parameter}\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported partition type\")\n",
        "\n",
        "        # Run the Leiden algorithm to detect communities\n",
        "        partition = leidenalg.find_partition(graph, partition_type, weights=None,\n",
        "                                             n_iterations=self.n_iter_leiden,\n",
        "                                             seed = self.random_seed,\n",
        "                                             **partition_kwargs)\n",
        "        self.labels = np.array(partition.membership)\n",
        "\n",
        "        return self.labels\n",
        "\n",
        "    def construct_graph_using_precomputed_neighbors(self):\n",
        "        n_cells = self.neighbor_graph.shape[0]\n",
        "        row_list, col_list, weight_list = [], [], []\n",
        "\n",
        "        for i in range(n_cells):\n",
        "            neighbors = self.neighbor_graph.indices[self.neighbor_graph.indptr[i]:self.neighbor_graph.indptr[i+1]]\n",
        "            distances = self.neighbor_graph.data[self.neighbor_graph.indptr[i]:self.neighbor_graph.indptr[i+1]]\n",
        "            to_keep = distances < (np.mean(distances) + self.dist_std_local * np.std(distances))\n",
        "\n",
        "            for j, keep in enumerate(to_keep):\n",
        "                if keep:\n",
        "                    row_list.append(i)\n",
        "                    col_list.append(neighbors[j])\n",
        "                    weight_list.append(1 / (distances[j] + 0.1))  # Inverse distance as weight\n",
        "\n",
        "        sparse_graph = scipy.sparse.csr_matrix((weight_list, (row_list, col_list)), shape=(n_cells, n_cells))\n",
        "        return self.apply_global_pruning(sparse_graph)\n",
        "\n",
        "    def construct_graph_using_hnsw(self):\n",
        "        self.hnsw.add_items(self.data)\n",
        "        neighbor_array, distance_array = self.hnsw.knn_query(self.data, k=self.knn)\n",
        "\n",
        "        n_cells = len(self.data)\n",
        "        row_list, col_list, weight_list = [], [], []\n",
        "\n",
        "        for i in range(n_cells):\n",
        "            dists = distance_array[i]\n",
        "            rows = neighbor_array[i]\n",
        "            to_keep = dists < (np.mean(dists) + self.dist_std_local * np.std(dists))\n",
        "\n",
        "            for j, keep in enumerate(to_keep):\n",
        "                if keep and i != rows[j]:  # Exclude self-loops\n",
        "                    row_list.append(i)\n",
        "                    col_list.append(rows[j])\n",
        "                    weight_list.append(1 / (dists[j] + 0.1))  # Inverse distance as weight\n",
        "\n",
        "        sparse_graph = scipy.sparse.csr_matrix((weight_list, (row_list, col_list)), shape=(n_cells, n_cells))\n",
        "        return self.apply_global_pruning(sparse_graph)\n",
        "\n",
        "    def apply_global_pruning(self, graph):\n",
        "        # Convert the sparse matrix to an adjacency list for igraph\n",
        "        sources, targets = graph.nonzero()\n",
        "        weights = graph.data\n",
        "        G = ig.Graph(edges=list(zip(sources, targets)), directed=False)\n",
        "        G.es['weight'] = weights\n",
        "\n",
        "        # Calculate Jaccard similarities and apply threshold\n",
        "        jaccard_similarities = G.similarity_jaccard(pairs=G.get_edgelist())\n",
        "        if self.jac_std_global == 'median':\n",
        "            threshold = np.median(jaccard_similarities)\n",
        "        else:\n",
        "            threshold = np.mean(jaccard_similarities) - self.jac_std_global * np.std(jaccard_similarities)\n",
        "\n",
        "        # Delete edges below the similarity threshold\n",
        "        edges_to_delete = [idx for idx, sim in enumerate(jaccard_similarities) if sim <= threshold]\n",
        "        G.delete_edges(edges_to_delete)\n",
        "\n",
        "        # Optionally simplify the graph to merge multiple edges and remove loops\n",
        "        G.simplify(multiple=True, loops=False)\n",
        "\n",
        "        return G\n",
        "\n",
        "    def convert_to_igraph(self, graph):\n",
        "        sources, targets = graph.nonzero()\n",
        "        G = ig.Graph(edges=list(zip(sources, targets)), directed=False)\n",
        "        G.es['weight'] = graph.data\n",
        "        return G"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTAG functions"
      ],
      "metadata": {
        "id": "9PuHf7__CT1H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i2-HS5mTjOf"
      },
      "outputs": [],
      "source": [
        "### UTAG helpers\n",
        "def message_passing(adata, mode=\"l1_norm\"):\n",
        "    \"\"\"\n",
        "    Applies a specified normalization to the adjacency matrix and propagates the data through it.\n",
        "    \"\"\"\n",
        "    if mode == \"l1_norm\":\n",
        "        connectivity_matrix = adata.obsp[\"spatial_connectivities\"]\n",
        "        modified_matrix = np.asarray(connectivity_matrix + np.eye(connectivity_matrix.shape[0]))\n",
        "        affinity = normalize(modified_matrix, axis=1, norm=\"l1\")\n",
        "    else:\n",
        "        affinity = adata.obsp[\"spatial_connectivities\"]\n",
        "    adata.X = affinity @ adata.X\n",
        "    return adata\n",
        "\n",
        "def add_probabilities_to_centroid(adata, column):\n",
        "    \"\"\"\n",
        "    Calculates and adds probability scores to the anndata object based on centroids.\n",
        "    \"\"\"\n",
        "    output_key = f\"{column}_probabilities\"\n",
        "    # Compute the mean of each group after z-score normalization directly within the pandas workflow\n",
        "    df = adata.to_df()\n",
        "    normalized_data = (df - df.min()) / (df.max() - df.min())\n",
        "    group_means = normalized_data.groupby(adata.obs[column]).mean()\n",
        "    probabilities = softmax(df.dot(group_means.T), axis=1)\n",
        "    adata.obsm[output_key] = probabilities\n",
        "    return adata\n",
        "\n",
        "def cluster_results(data, method, resolution, save_key):\n",
        "    \"\"\"\n",
        "    Conducts clustering on the data using specified method and resolution, adding the results to data.obs.\n",
        "    \"\"\"\n",
        "    cluster_key = f\"{save_key}_{method.lower()}_{resolution}\"\n",
        "    if method == 'LEIDEN':\n",
        "        sc.tl.leiden(data, resolution=resolution, key_added=cluster_key)\n",
        "    elif method == 'PARC':\n",
        "        model = PARC(data.obsm[\"X_pca\"], neighbor_graph=data.obsp[\"connectivities\"], resolution_parameter=resolution)\n",
        "        model.run_PARC()\n",
        "        data.obs[cluster_key] = pd.Categorical(model.labels)\n",
        "    add_probabilities_to_centroid(data, cluster_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def utag(adata,\n",
        "         slide_key=\"slide\",\n",
        "         save_key=\"UTAG Label\",\n",
        "         max_dist=20.0,\n",
        "         normalization_mode=\"l1_norm\",\n",
        "         pca_kwargs={'n_comps': 10},\n",
        "         clustering_methods=[\"leiden\", \"parc\"],\n",
        "         resolutions=[0.05, 0.1, 0.3, 1.0]):\n",
        "    \"\"\"\n",
        "    Processes and clusters single-cell imaging data by slides (if specified), using PCA for dimensionality reduction\n",
        "    followed by specified clustering methods.\n",
        "    \"\"\"\n",
        "    ad = adata.copy()\n",
        "\n",
        "    # Validate clustering methods\n",
        "    clustering_methods = [method.lower() for method in clustering_methods]\n",
        "    assert all(method in [\"leiden\", \"parc\"] for method in clustering_methods), \"Unsupported clustering method provided.\"\n",
        "\n",
        "    if slide_key and slide_key in ad.obs:\n",
        "        slide_data = {slide: ad[ad.obs[slide_key] == slide].copy() for slide in ad.obs[slide_key].unique()}\n",
        "    else:\n",
        "        slide_data = {None: ad}  # Process all data together if no slide_key provided\n",
        "\n",
        "    # Process each slide separately\n",
        "    for slide, data in slide_data.items():\n",
        "        print(f\"Processing slide: {slide}\")\n",
        "        sq.gr.spatial_neighbors(data, radius=max_dist, coord_type=\"generic\", set_diag=True)\n",
        "        data = message_passing(data, mode=normalization_mode)\n",
        "        sc.tl.pca(data, **pca_kwargs)\n",
        "        sc.pp.neighbors(data)\n",
        "\n",
        "        for resolution in resolutions:\n",
        "            for method in clustering_methods:\n",
        "                cluster_results(data, method, resolution, save_key)\n",
        "\n",
        "    # Combine slide results if processed separately\n",
        "    ad_result = anndata.concat(slide_data.values()) if slide_key in ad.obs else slide_data[None]\n",
        "\n",
        "    return ad_result"
      ],
      "metadata": {
        "id": "3QgJ176ylNEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lhA7oSaFQmoA",
        "G5iEhMXP6rHQ",
        "sph3r2tdBa-x",
        "9PuHf7__CT1H"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}