{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEYJTkA3CDj3"
      },
      "outputs": [],
      "source": [
        "import functions\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case channels are not stored in a seperate file, and the mask is not iteratively numbered. The following code block is the additional handling associated with extracting the metadata and cell segmentation mask"
      ],
      "metadata": {
        "id": "1qdpEk6TFAzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_tiff_path = \"/data/raw_data/lung_cancer/lung_cancer_features.tif\"\n",
        "mask_tiff_path = \"/data/raw_data/lung_cancer/lung_cancer_segmentation_mask.tif\"\n",
        "\n",
        "img_data, metadata = read_tiff_all_bands(feature_tiff_path)  # This will have shape (height, width, num_channels)\n",
        "mask_data = read_single_band(mask_tiff_path)\n",
        "\n",
        "mask = preprocess_mask(mask_data)\n",
        "\n",
        "# As the mask and the feature image does not have precisely the same dimensions\n",
        "cropped_img_data = crop_tiff_to_match_mask(img_data, mask_data.shape)\n",
        "\n",
        "# Extracting metadata from the feature image to get channels\n",
        "xml_content = metadata['TIFFTAG_IMAGEDESCRIPTION']\n",
        "\n",
        "# Parse the XML content\n",
        "root = ET.fromstring(xml_content)\n",
        "\n",
        "# Extract namespace (assuming it's in the 'xmlns' of the <OME> element)\n",
        "namespace = {'ome': 'http://www.openmicroscopy.org/Schemas/OME/2016-06'}\n",
        "\n",
        "# Initialize an empty list to collect channel data\n",
        "channels = []\n",
        "\n",
        "# Traverse the XML tree to extract channel information\n",
        "# Note the use of the namespace prefix in the XPath query\n",
        "for channel in root.findall('.//ome:Channel', namespace):\n",
        "    channel_id = channel.get('ID').split(':')[1]\n",
        "    channel_name = channel.get('Name')\n",
        "\n",
        "    # Append each channel's information as a dictionary to the channels list\n",
        "    channels.append({\n",
        "        '': channel_id,\n",
        "        'channel': channel_name,\n",
        "    })\n",
        "\n",
        "# Convert list of dictionaries to pandas DataFrame\n",
        "channels_df = pd.DataFrame(channels)[:48] # here removing 2 non-channels\n",
        "\n",
        "# Not including channels that will likely only lead to noise\n",
        "#print(channels_df)\n",
        "noisy_channels = {0,1,2,3,4,5,6,39,40,41,42,43,44,45,46,47}\n",
        "# removed channels: 80ArAr, 89Y, 120Sn, 127I, 131Xe, 138Ba, 140Ce, 189Os, 190BCKG, 191Ir_DNA1, 193Ir_DNA2, ICSK1, ICSK2, ICSK3, 202Hg, 208Pb\n",
        "\n",
        "# Calculate remaining channels by excluding noisy ones\n",
        "all_channels = set(range(cropped_img_data.shape[2]))\n",
        "remaining_channels = list(all_channels - noisy_channels)\n",
        "\n",
        "# Select the non-noisy channels\n",
        "filtered_img_data = cropped_img_data[:, :, remaining_channels]\n",
        "channels_df = channels_df.iloc[remaining_channels]\n",
        "\n",
        "data, cell_ids, centroids, dataScaleSize, cellSizes = extract_data_from_gdal_tiffs(filtered_img_data, mask)"
      ],
      "metadata": {
        "id": "EwC-DSSgEzT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The extracted data can then be used to either directly run UTAG"
      ],
      "metadata": {
        "id": "fJfgWvkMFbbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_channels = [i for i in range(filtered_img_data.shape[2])]  # Channels to include in the analysis\n",
        "unmod_adata = tif_create_data(filtered_img_data, cell_ids, centroids, data, channels_df, remaining_channels)\n",
        "\n",
        "utag_unmod = utag(\n",
        "    unmod_adata,\n",
        "    slide_key=\"roi\",\n",
        "    max_dist=15,\n",
        "    normalization_mode='l1_norm',\n",
        "    clustering_method = 'parc',\n",
        "    resolutions = [0.3]\n",
        ")"
      ],
      "metadata": {
        "id": "NdCCfKKXFhS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively REDSEA spillover compensation can be applied before clustering with   "
      ],
      "metadata": {
        "id": "tiZD7SSGFisO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running REDSEA\n",
        "data_compen_scale_size_cells, means, stdevs, valid_indices = redsea_compensation(data, mask, filtered_img_data, channels_df, feature_tiff_path,\n",
        "                                                                                 cell_sizes, element_shape=2, element_size=2)\n",
        "\n",
        "redsea_adata = create_anndata(data_compen_scale_size_cells, cell_ids, centroids, means, stdevs, channels_df, valid_indices)\n",
        "# Running UTAG\n",
        "utag_redsea = utag(\n",
        "    redsea_adata,\n",
        "    slide_key=\"roi\",\n",
        "    max_dist=15,\n",
        "    normalization_mode='l1_norm',\n",
        "    apply_clustering=True,\n",
        "    clustering_method = 'parc',\n",
        "    resolutions = [0.3]\n",
        ")"
      ],
      "metadata": {
        "id": "Fho6v0pHGPnC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}